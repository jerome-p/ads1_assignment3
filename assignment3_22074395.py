import cluster_tools as clst
import pandas as pd
import sklearn.cluster as cluster
import matplotlib.pyplot as plt
import sklearn.metrics as skmet
import numpy as np
import scipy.optimize as opt
import errors as err

def load_data(dataset, country_list):
    """
    This function takes in a csv file and a list of countries that are of
    interest. Returns two dataframes one with the years as columns and the
    other country names as columns. (Reused assignment_2's code to
                                     load dataset')

    Parameters
    ----------
    dataset : .csv file
    country_list : List
    
    Returns DF and transposed DF
    """
    # skipping first 4 rows, as they contain non essential data.
    world_bank_df = pd.read_csv(dataset, skiprows=4)

    # Removing non essential data.
    world_bank_df.drop(['Country Code', 'Indicator Code', 'Unnamed: 67'],
                       axis=1, inplace=True)

    # subsetting the dataframe to get data for countries we are interested in.
    world_bank_df = world_bank_df[
        world_bank_df['Country Name'].isin(country_list)]

    # Setting index before transposing the dataframe
    temp_df = world_bank_df.set_index('Country Name')

    return world_bank_df, temp_df.T

def subset_data(data,
                indicator1,indicator2,indicator3,indicator4,
                countries):
    """
    This function returns a susbset of the given dataframe. It returns a 
    dataframe with indicator values for each country appended column wise
    along with the country's name for each value.
    
    Returns DF

    """    
    
    # Selecting only the indicators needed from the dataset.
    data = data[
        (data['Indicator Name'] == indicator1) |
        (data['Indicator Name'] == indicator2) |
        (data['Indicator Name'] == indicator3) |
        (data['Indicator Name'] == indicator4)
    ]      
    
    result_df = pd.DataFrame()
    for country in countries:
        temp = data[data['Country Name'] == country]
        
        # Dropping Country Name column to make it easier to label
        # and the columns 1960 and 2022 have Na values
        temp = temp.drop(['Country Name', '1960', '2022'], axis=1)
        temp = temp.set_index('Indicator Name')
        temp = temp.T
        temp['Country'] = country
        result_df = pd.concat([result_df, temp], axis=0, ignore_index=True)
        
    return result_df


def sil_score(normalised_df):
    """
    This function generates the silhouette score for the given dataframe. It 
    uses the sklearn metrics module to generate the score. Using which we 
    the number of clusters can be decided.
    
    Parameters: DataFrame
    
    Returns None
    
    """
    
    for n in range(2,8):    

        ncluster = n
        
        kmeans = cluster.KMeans(n_clusters=ncluster, n_init=20)
        
        kmeans.fit(normalised_df)
        
        labels = kmeans.labels_
                
        print("Nclusters: "+str(n))
        print(skmet.silhouette_score(normalised_df, labels))
        
        return
        
def generate_kmeans_cluster_plot(result,normalised_df, indicator_1, 
                                 indicator_2, ncluster,
                                 min_values, max_values,
                                 ylabel):
    """
    This function generates a scatter plot using the kmeans algortihm. It 
    It helps visualise clusters of data. 
    
    Parameters: 
        result: DF
        normalised_df: DF
        indicator_1: String
        indicator_2: String
        ncluster: int
        max_values,min_values: Outputs from cluster tools scaler function.
        
    Returns: None
    
    """
    
    #performing kmeans clustering with the number of clusters provided.
    kmeans = cluster.KMeans(n_clusters=ncluster, n_init=20)
    
    #Fitting using normalised values
    kmeans.fit(normalised_df)
    #storing the labels generated by the algorithm
    labels = kmeans.labels_
    #Getting the centers of the clusters
    cen = kmeans.cluster_centers_
    #x and y values for the cluster centers. This is used to plot the centers
    xkmeans = cen[:,0]
    ykmeans = cen[:,1]
    #storing the labels into the result DF. The labels will be used to extract
    #country names using logical slicing.
    result['label'] = labels
    #Colormap
    cm = plt.colormaps["Paired"]
    
    plt.figure()
    #Plotting the clusters using normalised values
    plt.scatter(normalised_df[indicator_1], 
                normalised_df[indicator_2], marker="o", c=labels,
                cmap=cm)
    #plotting the kmeans centers
    plt.scatter(xkmeans, ykmeans, marker="d", label="kmeans centres", c='red')
    
    #Labeling
    plt.xlabel(indicator_1)
    plt.ylabel(ylabel)
    plt.legend()
    plt.show()

    #New figure, to generate clusters using the real values
    plt.figure()
    #Backscaling clusters to fit the real values
    backscaled_centers = clst.backscale(cen, min_values, max_values)
    x = backscaled_centers[:,0]
    y = backscaled_centers[:,1]
    
    #Getting the list of clusters generated by Kmeans algorithm.
    #Using logical slicing to extract the desired labels and the country 
    #name associated to that row.
    cluster_name = []
    for i in range(ncluster):
        cluster_name.append(result[result['label'] == i]['Country'].unique())
      
    #Creating an empty list using which we can store country names 
    #This list will be used to generate cluster label
    country_list = []    
    #Empty string, in which the country names will be appended.
    country_name = ""
    
    #Looping throught the
    for i in range(len(cluster_name)):
        for j in range(len(cluster_name[i])):
            country_name += cluster_name[i][j] + ", "
        country_list.append(country_name)
        country_name = ""
        
    #Printing what countries Kmeans has clustered together.   
    for i in range(len(country_list)):
        print("Kmeans Label "+str(i)+": "+ country_list[i])
            
    #Plotting each cluster for loop, this is being done so that the label 
    #can give us information for each cluster.    
    for i in result['label'].unique():
        plt.scatter(result[result['label'] == i][indicator_1],
                    result[result['label'] == i][indicator_2],
                    label=country_list[i])
   
    #Plotting original centers     
    plt.scatter(x, y, marker="d", label="original centres", c='black' )
    
    #Labelling
    plt.xlabel(indicator_1)
    plt.ylabel(ylabel)    
    plt.legend()
    plt.show()    
    
    return 
    

def exp_growth(t, scale, growth):
    """
    Computes exponential function with scale and growth as free parameters
    """
    
    f = scale * np.exp(growth * (t)) 
    
    return f

def exp_growth2(t, scale, growth):
    """
    Computes exponential function with scale and growth as free parameters
    """
    
    f = scale * np.exp(growth * (t-1970)) 
    
    return f

def curve_fit_plot(data, country, indicator, xlabel, ylabel, title):
    """
    This function fits a exponential function to a given data. In this case,
    the values of an indicator for a selected country.
    
    Returns None.

    """
    # Specifying figure size, as plot is big
    #plt.figure(figsize=(15, 8))

    temp_df = data[country].T
    # Subsetting the transposed df. Which now has years as columns
    subset_df = temp_df[temp_df['Indicator Name'] == indicator]
    # Transposing the df again to makes years the index.
    subset_df = subset_df.T
    
    #Manipulating the dataframe to get it into the required format
    #Resetting the index
    subset_df = subset_df.reset_index()
    #Dropping the first row
    subset_df = subset_df.drop(index=0)
    
    #Renaming the index to make it convinient to select data.
    subset_df = subset_df.rename(
        columns={'index': 'Year', 
                 country: indicator})
    
    #Converting the year data from string to int
    xdata = subset_df['Year'].astype(int)
    #Converting the selected indicator data to float type
    ydata = subset_df[indicator].astype(float)
    #Fitting the exp_growth function
    param, pcovar = opt.curve_fit(exp_growth, xdata, ydata, p0=(0,0))    
    #Storing the predicted values from the fitted model
    subset_df['pop_exp'] = exp_growth(xdata, *param)
    
    #Plotting the orginal data
    plt.figure()
    plt.plot(xdata,
             ydata, 
             label='Data')
    #Plotting the fitted data
    plt.plot(xdata, 
             subset_df['pop_exp'], 
             label='fit')
    
    #Labelling
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.legend()
    plt.title('Trial 1')
    plt.show()
    
    # Visualising Error for the fitted data, using the errors py file
    sigma = err.error_prop(xdata, exp_growth, param, pcovar)

    low = subset_df['pop_exp'] - sigma
    up = subset_df['pop_exp'] + sigma
    
    #Plotting data with errors ranges
    plt.figure()
    plt.title("exponenetial function error")
    plt.plot(xdata, ydata, label="data")
    plt.plot(xdata, subset_df['pop_exp'], label="fit")
    # plot error ranges with transparency
    plt.fill_between(xdata, low, up, alpha=0.2, color="green")
    #Labelling
    plt.legend(loc="upper left")
    plt.show()

    return 


def main():
    
    # Create a list of Countries interested in evaluating.
    countries = ['China', 'India', 'Japan',
                 'United Kingdom', 'United States', 'Germany']
    #loading dataset
    wb_data_years, wb_data_country = load_data(
        'climate_change.csv',
        countries)

    #Subsetting the dataset and getting it into desired format
    result = subset_data(wb_data_years,
                'CO2 emissions from solid fuel consumption (% of total)',
                'CO2 emissions (kt)',
                'Urban population (% of total population)',
                'Electric power consumption (kWh per capita)',
                countries)  
    #dropping Na values along row, as kmeans does not work with na values
    result = result.dropna(axis=0)
    
    
    # This produces a heatmap using cluster_tools py file.
    # The generated plot had to be saved maunally from spyder IDE.
    clst.map_corr(result)
    
    # Choosing indicators based on the heatmap
    indicator_1 = 'Urban population (% of total population)'
    indicator_2 = 'CO2 emissions from solid fuel consumption (% of total)'
    
    cluster_df = result[[indicator_1, indicator_2]]    
    scaler_output = clst.scaler(cluster_df)
    
    print(scaler_output[0])
    
    normalised_df = scaler_output[0]
    #Extracting min and max values from scaler ouput. 
    min_values = scaler_output[1]
    max_values = scaler_output[2]
    #Calculating siloheute score and choosing no.of clusters
    sil_score(normalised_df)
    n_cluster = 2
    #Generating kmeans clusters
    generate_kmeans_cluster_plot(result,normalised_df,
                                 indicator_1, indicator_2, 
                                 n_cluster, min_values, max_values,
                                 "CO2 % of total, from solid fuel consumption")
    
    # Choosing indicators based on the heatmap
    indicator_1 = 'Electric power consumption (kWh per capita)'
    indicator_2 = 'Urban population (% of total population)'
    
    cluster_df = result[[indicator_1, indicator_2]]
    #Using the cluster tool py file to normalise and get min and max values
    scaler_output = clst.scaler(cluster_df)
    normalised_df = scaler_output[0]
    min_values = scaler_output[1]
    max_values = scaler_output[2]
    
    #Cluster plot 2
    #Calculating siloheute score and choosing no.of clusters
    sil_score(normalised_df)
    n_cluster = 3
    labeled_df = generate_kmeans_cluster_plot(result,normalised_df,
                                              indicator_1, indicator_2, 
                                 n_cluster, min_values, max_values,
                                 indicator_2)
    
    #Fitting a exponential function for India's Urban population %
    curve_fit_plot(wb_data_country,
                       'India',
                       'Urban population (% of total population)',
                       'Years','urbanpop','Trialdank')
        
    return wb_data_years, wb_data_country, result, labeled_df, scaler_output



if __name__ == '__main__':
    years, countries, result, labeled, scaler = main()
